{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukec\\PycharmProjects\\emissions-tracking-conda\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\lukec\\PycharmProjects\\emissions-tracking-conda"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "# %%writefile functions/graph_utilities.py\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from more_itertools import locate\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def concat_lists(lists):\n",
    "    \"\"\"List concatenation utility function\"\"\"\n",
    "    return list(itertools.chain.from_iterable(lists))\n",
    "\n",
    "def pd_to_adj_matrix(df:pd.DataFrame, columns:list, weights=False):\n",
    "    \"\"\"Form adjacency matrix from pandas dataframe columns\"\"\"\n",
    "    adj, edgeWeights = np.zeros([2,0]), []\n",
    "    for i, column in enumerate(columns):\n",
    "        edgeDest = [list(locate(df[column], lambda x: x==i)) for i in df[column]]\n",
    "        edgeOrig = concat_lists([list(np.ones(len(x)).astype(int)*i) for i, x in enumerate(edgeDest)])\n",
    "        edgeDest = concat_lists(edgeDest)\n",
    "        nonSelf = np.where([val!=edgeDest[i] for i, val in enumerate(edgeOrig)])[0]\n",
    "        adj = np.concatenate((adj,np.array([np.take(edgeOrig,nonSelf), np.take(edgeDest,nonSelf)])),axis=-1)\n",
    "        if weights: edgeWeights = edgeWeights + [weights[i]]*len(edgeDest)\n",
    "    return adj.astype(int), edgeWeights\n",
    "\n",
    "def encode_string_cols(df):\n",
    "    \"\"\"Encodes columns of a pandas dataframe with string dtype as integer classes\"\"\"\n",
    "    ord_enc = OrdinalEncoder()\n",
    "    columns = df.columns[[i in [object, str] for i in df.dtypes]]\n",
    "    for col in columns:\n",
    "        df[col] = ord_enc.fit_transform(df[col].values.reshape(-1,1))\n",
    "    return df\n",
    "\n",
    "def build(df, edges:list, y_col=False, bins=False):\n",
    "    \"\"\"This function builds a graph given a Pandas DataFrame\"\"\"\n",
    "    adjacency, _ = pd_to_adj_matrix(df, edges)\n",
    "    edge_index = torch.tensor(adjacency, dtype=torch.long)\n",
    "    data_x = df.drop(y_col, axis=1) if y_col else df\n",
    "    x = torch.tensor(encode_string_cols(data_x).values, dtype=torch.float)\n",
    "\n",
    "    if y_col:\n",
    "        if bins:\n",
    "            y = torch.tensor(np.digitize(df[y_col],\n",
    "                             bins= np.linspace(min(df[y_col].dropna()),max(df[y_col].dropna()),bins))-1,\n",
    "                             dtype= torch.long)\n",
    "        else: y = torch.tensor(df[y_col], dtype=torch.float)\n",
    "        return Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "    else: return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "def draw_pyg_graph(data, node_size=50, width=0.1, cmap=plt.cm.coolwarm):\n",
    "    graph = to_networkx(data, to_undirected=True)\n",
    "    pos = nx.kamada_kawai_layout(graph)\n",
    "    fig, ax = plt.subplots(1,1,figsize=[12,12])\n",
    "    nx.draw_networkx(graph,pos, with_labels=False,node_size=node_size,width=width, node_color=data.y, cmap=cmap)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "# %%writefile functions/node_classification\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"Graph Convolutional Network model\"\"\"\n",
    "    def __init__(self, dataset, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(123)\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, len(dataset.y.unique()))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def train(data, model, optimizer, criterion = torch.nn.CrossEntropyLoss()):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test(data, model):\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "def run(data, model, optimizer, verbose=True):\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train(data, model, optimizer)\n",
    "        if verbose: print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "    test_acc = test(graph, model)\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "def visualize(h, color):\n",
    "    \"\"\"Define TSNE visualisation\"\"\"\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# %%writefile scripts/graph_run.py\n",
    "\n",
    "import pandas as pd\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "# Build graph\n",
    "data = pd.read_csv(\"C:/Users\\lukec\\OneDrive - University of Cambridge\\PhD\\Data\\Aggregate/US_2019.csv\", low_memory=False).dropna(subset='CO2e')\n",
    "graph = build(data, ['PRODUCT','SITE'], y_col='CO2e', bins=6)\n",
    "\n",
    "#draw_pyg_graph(graph)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 5 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_4000/3553713709.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mGCN_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGCN\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgraph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhidden_channels\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m30\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0moptimizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mAdam\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mGCN_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight_decay\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5e-4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgraph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mGCN_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_4000/3521075479.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(data, model, optimizer, verbose)\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m101\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 42\u001B[1;33m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     43\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf'Epoch: {epoch:03d}, Loss: {loss:.4f}'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_4000/3521075479.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(data, model, optimizer, criterion)\u001B[0m\n\u001B[0;32m     25\u001B[0m       \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Clear gradients.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m       \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0medge_index\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Perform a single forward pass.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m       \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_mask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_mask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Compute the loss solely based on the training nodes.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m       \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Derive gradients.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m       \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Update parameters based on gradients.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m   1148\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1150\u001B[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001B[0m\u001B[0;32m   1151\u001B[0m                                \u001B[0mignore_index\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mignore_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreduction\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1152\u001B[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\emissions-tracking-conda\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[0;32m   2844\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0msize_average\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mreduce\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2845\u001B[0m         \u001B[0mreduction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_Reduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlegacy_get_string\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize_average\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2846\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcross_entropy_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_Reduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_enum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreduction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel_smoothing\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2847\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2848\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: Target 5 is out of bounds."
     ]
    }
   ],
   "source": [
    "# Run classification\n",
    "\"\"\"Train & evaluate GCN model\"\"\"\n",
    "RandomNodeSplit('train_rest', num_val=50, num_test=50)(graph)\n",
    "GCN_model = GCN(graph, hidden_channels=30)\n",
    "optimizer = torch.optim.Adam(GCN_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "run(graph, GCN_model, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([308,  12,   6,   0,   3])"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "out = model(data.x, data.edge_index)\n",
    "visualize(out, color=data.y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}