{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Variable definition\n",
    "filepath = \"C:/Users\\lukec\\OneDrive - University of Cambridge\\Projects\\PhD\\Data\\pdfs\\iron ore beneficiation_IN_2017_Undefined.pdf\"\n",
    "keywords, split = ['Pedigree matrix','Comment'], ['Detailed Information For Exchanges','Inputs from','Emissions']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# Extract text from pdf\n",
    "pdf_text = str(list(map(lambda x: x.extract_text(), pdfplumber.open(filepath).pages)))\n",
    "\n",
    "text = pdf_text[list(re.finditer(split[0], pdf_text))[1].end():] # Filter out header pages\n",
    "locs1, locs2 = [list(map(lambda x: x.end(), list(re.finditer(kw, text)))) for kw in keywords] # Find keyword locations\n",
    "pedigrees = list(map(lambda x: ast.literal_eval(text[x+2:x+17]), locs1)) # Pedigree matrices to list\n",
    "\n",
    "# Extract names of inputs/outputs\n",
    "val_lines = list(map(lambda x: list(re.finditer(r\"\\\\n\",text[:x]))[-2].end(),locs2)) # Get values for start of section preceding keyword\n",
    "val_lines = np.array(list(map(lambda x,y: list(re.finditer(r\"\\\\n\",text[:x]))[-3].end() if 'Activity' in text[y:y+10] else y, locs2, val_lines)))\n",
    "val_lines += list(map(lambda x: re.search('[a-zA-z]',text[x:]).start(),val_lines)) # Find first letter (caters for new pages etc...)\n",
    "num_starts = list(map(lambda x: re.search(\"\\d+\\.\\d+\",text[x:]).start(), val_lines)) # Find start of value for each process\n",
    "num_ends = list(map(lambda x: re.search('\\s',text[x:]).end(), (np.array(val_lines)+num_starts)))\n",
    "components = list(map(lambda x,y: text[x:x+y],val_lines,np.array(num_starts)-1))\n",
    "quantities = list(map(lambda x,y: text[x:x+y],np.array(val_lines)+num_starts,num_ends))\n",
    "\n",
    "#info_start = list(re.finditer(split[0], text))[1].end()\n",
    "input_output_switch = list(map(lambda x: list(re.finditer(x, text))[0].end(),split[1:]))\n",
    "#features = list(re.finditer(keywords[0], text))\n",
    "\n",
    "process = pd.DataFrame(np.array([components,quantities,pedigrees]).transpose(),columns=['components','quantities','pedigrees'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "2144"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract from EcoSpold xmls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}